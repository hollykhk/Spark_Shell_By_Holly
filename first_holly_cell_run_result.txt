databricks-logoScala>Python(Scala) Import Notebook

First Cell
import org.apache.spark.mllib.evaluation.MulticlassMetrics
import org.apache.spark.mllib.classification.{LogisticRegressionWithLBFGS, LogisticRegressionModel}
import org.apache.spark.mllib.regression.LabeledPoint
import org.apache.spark.mllib.linalg.{Vector, Vectors}
val data = sc.textFile("/FileStore/tables/qt5qvaey1491163359132")
data.count()
// display contents of data RDD
data.collect().foreach(println)
// let's convert qualitative variables to quantitative ones
def getDoubleValue( input:String ) : Double = {
    var result:Double = 0.0
    if (input == "P")  result = 3.0 
    if (input == "A")  result = 2.0
    if (input == "N")  result = 1.0
    if (input == "NB") result = 1.0
    if (input == "B")  result = 0.0
    return result
   }
// note that the column at index 6 is the class label and the rest are features
val parsedData = data.map{line => 
    val parts = line.split(",")
    LabeledPoint(getDoubleValue(parts(6)), Vectors.dense(parts.slice(0,6).map(x => getDoubleValue(x))))
}
// display contents of parsedData RDD
parsedData.collect().foreach(println)
// another way
println(parsedData.take(10).mkString("\n"))
// for classification, you need training and test parts. You want to randomly split data into train and test
val splits = parsedData.randomSplit(Array(0.6, 0.4), seed = 11L)
val trainingData = splits(0)
val testData = splits(1)
// check the data
trainingData.take(10).foreach(println)
// train the model
val model = new LogisticRegressionWithLBFGS().setNumClasses(2).run(trainingData)
// dataframe way to do it
val parsedData1 = data.map{line => 
     line.split(",").map(getDoubleValue).mkString(",")
}
val labelAndPreds = testData.map { point =>
  val prediction = model.predict(point.features)
  (point.label, prediction)
}
val trainErr = labelAndPreds.filter(r => r._1 != r._2).count.toDouble / testData.count
println("Training Error = " + trainErr)

P,P,A,A,A,P,NB
N,N,A,A,A,N,NB
A,A,A,A,A,A,NB
P,P,P,P,P,P,NB
N,N,P,P,P,N,NB
A,A,P,P,P,A,NB
P,P,A,P,P,P,NB
P,P,P,A,A,P,NB
P,P,A,P,A,P,NB
P,P,A,A,P,P,NB
P,P,P,P,A,P,NB
P,P,P,A,P,P,NB
N,N,A,P,P,N,NB
N,N,P,A,A,N,NB
N,N,A,P,A,N,NB
N,N,A,P,A,N,NB
N,N,A,A,P,N,NB
N,N,P,P,A,N,NB
N,N,P,A,P,N,NB
A,A,A,P,P,A,NB
A,A,P,A,A,A,NB
A,A,A,P,A,A,NB
A,A,A,A,P,A,NB
A,A,P,P,A,A,NB
A,A,P,A,P,A,NB
P,N,A,A,A,P,NB
N,P,A,A,A,N,NB
P,N,A,A,A,N,NB
P,N,P,P,P,P,NB
N,P,P,P,P,N,NB
P,N,P,P,P,N,NB
N,N,A,P,P,P,NB
P,N,P,A,A,P,NB
N,P,A,P,A,P,NB
N,P,A,A,P,N,NB
P,N,P,P,A,N,NB
N,P,P,A,P,A,NB
A,N,A,P,P,A,NB
A,P,P,A,A,A,NB
A,A,A,P,A,P,NB
A,A,A,A,P,N,NB
N,A,P,P,P,N,NB
A,N,P,A,P,N,NB
A,P,P,A,P,N,NB
N,N,P,A,P,P,NB
N,N,P,P,P,P,NB
P,A,P,P,P,N,NB
A,P,P,P,P,N,NB
A,N,N,A,P,P,NB
A,P,P,A,P,P,NB
P,A,P,A,P,N,NB
A,N,A,A,P,P,NB
A,N,A,A,P,N,NB
A,N,A,A,P,A,NB
A,A,N,P,P,A,NB
A,A,N,P,P,P,NB
A,P,P,P,P,P,NB
A,P,A,A,A,P,NB
N,P,N,P,P,A,NB
N,N,P,P,P,A,NB
A,A,A,P,P,A,NB
A,A,A,P,P,P,NB
P,A,A,P,P,P,NB
A,N,N,P,P,A,NB
P,N,N,P,P,A,NB
A,A,N,P,P,P,NB
P,A,P,N,P,N,NB
P,A,N,A,P,N,NB
P,P,P,A,P,N,NB
P,A,P,N,P,N,NB
P,A,A,P,P,N,NB
P,P,A,P,P,P,NB
P,A,P,A,P,P,NB
P,P,A,A,P,N,NB
A,A,A,A,A,P,NB
P,P,A,P,P,N,NB
A,P,N,P,A,P,NB
A,P,A,P,A,P,NB
P,A,N,A,P,A,NB
A,P,N,P,A,P,NB
P,A,A,A,P,A,NB
A,P,A,P,A,P,NB
A,P,P,P,P,P,NB
P,A,A,N,P,P,NB
A,P,A,A,A,P,NB
A,N,N,N,P,P,NB
N,P,N,P,P,A,NB
P,N,A,N,A,P,NB
N,N,P,P,P,A,NB
A,A,A,P,P,A,NB
A,A,A,P,P,P,NB
P,A,A,P,P,P,NB
A,N,N,P,P,A,NB
A,A,N,P,P,P,NB
P,A,P,N,P,N,NB
P,P,P,A,P,N,NB
P,A,P,N,P,N,NB
P,A,A,P,P,N,NB
P,P,A,P,P,P,NB
P,A,P,A,P,P,NB
P,P,A,A,P,N,NB
A,A,A,A,A,P,NB
P,P,A,P,P,N,NB
A,P,N,P,A,P,NB
P,A,A,A,P,A,NB
A,P,A,P,A,P,NB
A,P,N,P,A,P,NB
A,P,A,P,A,P,NB
P,P,A,A,A,P,NB
N,N,A,A,A,N,NB
A,A,A,A,A,A,NB
P,P,P,P,P,P,NB
N,N,P,P,P,N,NB
A,A,P,P,P,A,NB
P,P,A,P,P,P,NB
P,P,P,A,A,P,NB
P,P,A,P,A,P,NB
P,P,A,A,P,P,NB
P,P,P,P,A,P,NB
P,P,P,A,P,P,NB
N,N,A,P,P,N,NB
N,N,P,A,A,N,NB
N,N,A,P,A,N,NB
N,N,A,P,A,N,NB
N,N,A,A,P,N,NB
N,N,P,P,A,N,NB
N,N,P,A,P,N,NB
A,A,A,P,P,A,NB
A,A,P,A,A,A,NB
A,A,A,P,A,A,NB
A,A,A,A,P,A,NB
A,A,P,P,A,A,NB
A,A,P,A,P,A,NB
P,N,A,A,A,P,NB
N,P,A,A,A,N,NB
P,N,A,A,A,N,NB
P,N,P,P,P,P,NB
N,P,P,P,P,N,NB
P,N,P,P,P,N,NB
N,N,A,P,P,P,NB
P,N,P,A,A,P,NB
N,P,A,P,A,P,NB
N,P,A,A,P,N,NB
A,N,N,N,N,A,B
P,N,N,N,N,N,B
N,P,N,N,N,N,B
A,P,N,A,N,N,B
N,N,N,N,N,N,B
N,N,N,A,N,A,B
N,N,N,N,N,P,B
N,N,N,N,N,A,B
N,N,N,A,N,P,B
N,N,N,A,N,N,B
N,N,A,N,N,N,B
P,N,N,N,N,N,B
A,N,N,N,N,N,B
N,N,N,N,N,N,B
P,N,N,N,A,A,B
A,N,N,N,N,A,B
A,N,N,N,N,A,B
A,A,N,N,N,P,B
A,N,N,N,N,N,B
P,A,N,N,N,A,B
P,N,N,N,N,P,B
P,A,N,N,N,N,B
P,N,N,N,N,N,B
N,A,N,N,N,P,B
N,N,N,N,N,A,B
A,A,N,N,N,N,B
A,A,N,N,N,N,B
P,P,N,N,N,N,B
A,P,N,N,N,N,B
P,A,N,N,N,N,B
A,N,N,N,N,N,B
N,N,N,N,N,N,B
N,A,N,N,N,N,B
P,N,N,N,N,N,B
N,P,N,N,N,N,B
A,P,N,A,N,N,B
N,N,N,P,N,P,B
N,N,N,N,N,N,B
N,N,N,A,N,A,B
N,N,N,P,N,N,B
N,N,N,N,N,P,B
N,N,N,N,N,A,B
N,N,N,A,N,P,B
N,N,N,A,N,N,B
N,N,A,N,N,N,B
P,N,N,N,N,N,B
A,N,N,N,N,N,B
N,N,N,N,N,N,B
P,N,N,N,A,A,B
P,N,N,N,A,A,B
A,N,N,N,N,A,B
N,N,N,N,N,A,B
N,P,N,N,N,N,B
A,P,N,A,N,N,B
N,N,N,N,N,N,B
N,N,N,A,N,A,B
N,N,N,P,N,N,B
N,N,N,N,N,P,B
N,N,N,N,N,A,B
N,N,N,A,N,P,B
P,N,N,N,N,P,B
P,A,N,N,N,N,B
P,N,N,N,N,N,B
N,A,N,N,N,P,B
N,N,N,N,N,A,B
A,A,N,N,N,N,B
A,A,N,N,N,N,B
N,N,N,A,N,N,B
N,N,A,N,N,N,B
P,N,N,N,N,N,B
A,N,N,N,N,N,B
N,N,N,N,N,N,B
N,A,P,A,N,P,B
P,N,N,N,N,N,B
N,A,N,N,N,P,B
N,N,N,N,N,A,B
A,A,N,N,N,N,B
A,A,N,N,N,P,B
A,N,N,N,N,N,B
P,A,N,N,N,A,B
P,N,N,N,N,P,B
P,A,N,N,N,N,B
P,N,N,N,N,N,B
N,A,N,N,N,P,B
N,N,N,N,N,A,B
A,A,N,N,N,N,B
A,A,N,N,N,N,B
A,P,N,N,N,N,B
P,A,N,N,N,N,B
A,N,N,N,N,N,B
N,N,N,N,N,N,B
N,A,N,N,N,N,B
A,N,N,N,N,A,B
P,N,N,N,N,N,B
N,P,N,N,N,N,B
A,P,N,A,N,N,B
N,N,N,N,N,N,B
N,N,N,A,N,A,B
N,N,N,N,N,P,B
N,N,N,N,N,A,B
N,N,N,A,N,P,B
N,N,N,A,N,N,B
N,N,A,N,N,N,B
P,N,N,N,N,N,B
A,N,N,N,N,N,B
N,N,N,N,N,N,B
P,N,N,N,A,A,B
(1.0,[3.0,3.0,2.0,2.0,2.0,3.0])
(1.0,[1.0,1.0,2.0,2.0,2.0,1.0])
(1.0,[2.0,2.0,2.0,2.0,2.0,2.0])
(1.0,[3.0,3.0,3.0,3.0,3.0,3.0])
(1.0,[1.0,1.0,3.0,3.0,3.0,1.0])
(1.0,[2.0,2.0,3.0,3.0,3.0,2.0])
(1.0,[3.0,3.0,2.0,3.0,3.0,3.0])
(1.0,[3.0,3.0,3.0,2.0,2.0,3.0])
(1.0,[3.0,3.0,2.0,3.0,2.0,3.0])
(1.0,[3.0,3.0,2.0,2.0,3.0,3.0])
(1.0,[3.0,3.0,3.0,3.0,2.0,3.0])
(1.0,[3.0,3.0,3.0,2.0,3.0,3.0])
(1.0,[1.0,1.0,2.0,3.0,3.0,1.0])
(1.0,[1.0,1.0,3.0,2.0,2.0,1.0])
(1.0,[1.0,1.0,2.0,3.0,2.0,1.0])
(1.0,[1.0,1.0,2.0,3.0,2.0,1.0])
(1.0,[1.0,1.0,2.0,2.0,3.0,1.0])
(1.0,[1.0,1.0,3.0,3.0,2.0,1.0])
(1.0,[1.0,1.0,3.0,2.0,3.0,1.0])
(1.0,[2.0,2.0,2.0,3.0,3.0,2.0])
(1.0,[2.0,2.0,3.0,2.0,2.0,2.0])
(1.0,[2.0,2.0,2.0,3.0,2.0,2.0])
(1.0,[2.0,2.0,2.0,2.0,3.0,2.0])
(1.0,[2.0,2.0,3.0,3.0,2.0,2.0])
(1.0,[2.0,2.0,3.0,2.0,3.0,2.0])
(1.0,[3.0,1.0,2.0,2.0,2.0,3.0])
(1.0,[1.0,3.0,2.0,2.0,2.0,1.0])
(1.0,[3.0,1.0,2.0,2.0,2.0,1.0])
(1.0,[3.0,1.0,3.0,3.0,3.0,3.0])
(1.0,[1.0,3.0,3.0,3.0,3.0,1.0])
(1.0,[3.0,1.0,3.0,3.0,3.0,1.0])
(1.0,[1.0,1.0,2.0,3.0,3.0,3.0])
(1.0,[3.0,1.0,3.0,2.0,2.0,3.0])
(1.0,[1.0,3.0,2.0,3.0,2.0,3.0])
(1.0,[1.0,3.0,2.0,2.0,3.0,1.0])
(1.0,[3.0,1.0,3.0,3.0,2.0,1.0])
(1.0,[1.0,3.0,3.0,2.0,3.0,2.0])
(1.0,[2.0,1.0,2.0,3.0,3.0,2.0])
(1.0,[2.0,3.0,3.0,2.0,2.0,2.0])
(1.0,[2.0,2.0,2.0,3.0,2.0,3.0])
(1.0,[2.0,2.0,2.0,2.0,3.0,1.0])
(1.0,[1.0,2.0,3.0,3.0,3.0,1.0])
(1.0,[2.0,1.0,3.0,2.0,3.0,1.0])
(1.0,[2.0,3.0,3.0,2.0,3.0,1.0])
(1.0,[1.0,1.0,3.0,2.0,3.0,3.0])
(1.0,[1.0,1.0,3.0,3.0,3.0,3.0])
(1.0,[3.0,2.0,3.0,3.0,3.0,1.0])
(1.0,[2.0,3.0,3.0,3.0,3.0,1.0])
(1.0,[2.0,1.0,1.0,2.0,3.0,3.0])
(1.0,[2.0,3.0,3.0,2.0,3.0,3.0])
(1.0,[3.0,2.0,3.0,2.0,3.0,1.0])
(1.0,[2.0,1.0,2.0,2.0,3.0,3.0])
(1.0,[2.0,1.0,2.0,2.0,3.0,1.0])
(1.0,[2.0,1.0,2.0,2.0,3.0,2.0])
(1.0,[2.0,2.0,1.0,3.0,3.0,2.0])
(1.0,[2.0,2.0,1.0,3.0,3.0,3.0])
(1.0,[2.0,3.0,3.0,3.0,3.0,3.0])
(1.0,[2.0,3.0,2.0,2.0,2.0,3.0])
(1.0,[1.0,3.0,1.0,3.0,3.0,2.0])
(1.0,[1.0,1.0,3.0,3.0,3.0,2.0])
(1.0,[2.0,2.0,2.0,3.0,3.0,2.0])
(1.0,[2.0,2.0,2.0,3.0,3.0,3.0])
(1.0,[3.0,2.0,2.0,3.0,3.0,3.0])
(1.0,[2.0,1.0,1.0,3.0,3.0,2.0])
(1.0,[3.0,1.0,1.0,3.0,3.0,2.0])
(1.0,[2.0,2.0,1.0,3.0,3.0,3.0])
(1.0,[3.0,2.0,3.0,1.0,3.0,1.0])
(1.0,[3.0,2.0,1.0,2.0,3.0,1.0])
(1.0,[3.0,3.0,3.0,2.0,3.0,1.0])
(1.0,[3.0,2.0,3.0,1.0,3.0,1.0])
(1.0,[3.0,2.0,2.0,3.0,3.0,1.0])
(1.0,[3.0,3.0,2.0,3.0,3.0,3.0])
(1.0,[3.0,2.0,3.0,2.0,3.0,3.0])
(1.0,[3.0,3.0,2.0,2.0,3.0,1.0])
(1.0,[2.0,2.0,2.0,2.0,2.0,3.0])
(1.0,[3.0,3.0,2.0,3.0,3.0,1.0])
(1.0,[2.0,3.0,1.0,3.0,2.0,3.0])
(1.0,[2.0,3.0,2.0,3.0,2.0,3.0])
(1.0,[3.0,2.0,1.0,2.0,3.0,2.0])
(1.0,[2.0,3.0,1.0,3.0,2.0,3.0])
(1.0,[3.0,2.0,2.0,2.0,3.0,2.0])
(1.0,[2.0,3.0,2.0,3.0,2.0,3.0])
(1.0,[2.0,3.0,3.0,3.0,3.0,3.0])
(1.0,[3.0,2.0,2.0,1.0,3.0,3.0])
(1.0,[2.0,3.0,2.0,2.0,2.0,3.0])
(1.0,[2.0,1.0,1.0,1.0,3.0,3.0])
(1.0,[1.0,3.0,1.0,3.0,3.0,2.0])
(1.0,[3.0,1.0,2.0,1.0,2.0,3.0])
(1.0,[1.0,1.0,3.0,3.0,3.0,2.0])
(1.0,[2.0,2.0,2.0,3.0,3.0,2.0])
(1.0,[2.0,2.0,2.0,3.0,3.0,3.0])
(1.0,[3.0,2.0,2.0,3.0,3.0,3.0])
(1.0,[2.0,1.0,1.0,3.0,3.0,2.0])
(1.0,[2.0,2.0,1.0,3.0,3.0,3.0])
(1.0,[3.0,2.0,3.0,1.0,3.0,1.0])
(1.0,[3.0,3.0,3.0,2.0,3.0,1.0])
(1.0,[3.0,2.0,3.0,1.0,3.0,1.0])
(1.0,[3.0,2.0,2.0,3.0,3.0,1.0])
(1.0,[3.0,3.0,2.0,3.0,3.0,3.0])
(1.0,[3.0,2.0,3.0,2.0,3.0,3.0])
(1.0,[3.0,3.0,2.0,2.0,3.0,1.0])
(1.0,[2.0,2.0,2.0,2.0,2.0,3.0])
(1.0,[3.0,3.0,2.0,3.0,3.0,1.0])
(1.0,[2.0,3.0,1.0,3.0,2.0,3.0])
(1.0,[3.0,2.0,2.0,2.0,3.0,2.0])
(1.0,[2.0,3.0,2.0,3.0,2.0,3.0])
(1.0,[2.0,3.0,1.0,3.0,2.0,3.0])
(1.0,[2.0,3.0,2.0,3.0,2.0,3.0])
(1.0,[3.0,3.0,2.0,2.0,2.0,3.0])
(1.0,[1.0,1.0,2.0,2.0,2.0,1.0])
(1.0,[2.0,2.0,2.0,2.0,2.0,2.0])
(1.0,[3.0,3.0,3.0,3.0,3.0,3.0])
(1.0,[1.0,1.0,3.0,3.0,3.0,1.0])
(1.0,[2.0,2.0,3.0,3.0,3.0,2.0])
(1.0,[3.0,3.0,2.0,3.0,3.0,3.0])
(1.0,[3.0,3.0,3.0,2.0,2.0,3.0])
(1.0,[3.0,3.0,2.0,3.0,2.0,3.0])
(1.0,[3.0,3.0,2.0,2.0,3.0,3.0])
(1.0,[3.0,3.0,3.0,3.0,2.0,3.0])
(1.0,[3.0,3.0,3.0,2.0,3.0,3.0])
(1.0,[1.0,1.0,2.0,3.0,3.0,1.0])
(1.0,[1.0,1.0,3.0,2.0,2.0,1.0])
(1.0,[1.0,1.0,2.0,3.0,2.0,1.0])
(1.0,[1.0,1.0,2.0,3.0,2.0,1.0])
(1.0,[1.0,1.0,2.0,2.0,3.0,1.0])
(1.0,[1.0,1.0,3.0,3.0,2.0,1.0])
(1.0,[1.0,1.0,3.0,2.0,3.0,1.0])
(1.0,[2.0,2.0,2.0,3.0,3.0,2.0])
(1.0,[2.0,2.0,3.0,2.0,2.0,2.0])
(1.0,[2.0,2.0,2.0,3.0,2.0,2.0])
(1.0,[2.0,2.0,2.0,2.0,3.0,2.0])
(1.0,[2.0,2.0,3.0,3.0,2.0,2.0])
(1.0,[2.0,2.0,3.0,2.0,3.0,2.0])
(1.0,[3.0,1.0,2.0,2.0,2.0,3.0])
(1.0,[1.0,3.0,2.0,2.0,2.0,1.0])
(1.0,[3.0,1.0,2.0,2.0,2.0,1.0])
(1.0,[3.0,1.0,3.0,3.0,3.0,3.0])
(1.0,[1.0,3.0,3.0,3.0,3.0,1.0])
(1.0,[3.0,1.0,3.0,3.0,3.0,1.0])
(1.0,[1.0,1.0,2.0,3.0,3.0,3.0])
(1.0,[3.0,1.0,3.0,2.0,2.0,3.0])
(1.0,[1.0,3.0,2.0,3.0,2.0,3.0])
(1.0,[1.0,3.0,2.0,2.0,3.0,1.0])
(0.0,[2.0,1.0,1.0,1.0,1.0,2.0])
(0.0,[3.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[1.0,3.0,1.0,1.0,1.0,1.0])
(0.0,[2.0,3.0,1.0,2.0,1.0,1.0])
(0.0,[1.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[1.0,1.0,1.0,2.0,1.0,2.0])
(0.0,[1.0,1.0,1.0,1.0,1.0,3.0])
(0.0,[1.0,1.0,1.0,1.0,1.0,2.0])
(0.0,[1.0,1.0,1.0,2.0,1.0,3.0])
(0.0,[1.0,1.0,1.0,2.0,1.0,1.0])
(0.0,[1.0,1.0,2.0,1.0,1.0,1.0])
(0.0,[3.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[2.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[1.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[3.0,1.0,1.0,1.0,2.0,2.0])
(0.0,[2.0,1.0,1.0,1.0,1.0,2.0])
(0.0,[2.0,1.0,1.0,1.0,1.0,2.0])
(0.0,[2.0,2.0,1.0,1.0,1.0,3.0])
(0.0,[2.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[3.0,2.0,1.0,1.0,1.0,2.0])
(0.0,[3.0,1.0,1.0,1.0,1.0,3.0])
(0.0,[3.0,2.0,1.0,1.0,1.0,1.0])
(0.0,[3.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[1.0,2.0,1.0,1.0,1.0,3.0])
(0.0,[1.0,1.0,1.0,1.0,1.0,2.0])
(0.0,[2.0,2.0,1.0,1.0,1.0,1.0])
(0.0,[2.0,2.0,1.0,1.0,1.0,1.0])
(0.0,[3.0,3.0,1.0,1.0,1.0,1.0])
(0.0,[2.0,3.0,1.0,1.0,1.0,1.0])
(0.0,[3.0,2.0,1.0,1.0,1.0,1.0])
(0.0,[2.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[1.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[1.0,2.0,1.0,1.0,1.0,1.0])
(0.0,[3.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[1.0,3.0,1.0,1.0,1.0,1.0])
(0.0,[2.0,3.0,1.0,2.0,1.0,1.0])
(0.0,[1.0,1.0,1.0,3.0,1.0,3.0])
(0.0,[1.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[1.0,1.0,1.0,2.0,1.0,2.0])
(0.0,[1.0,1.0,1.0,3.0,1.0,1.0])
(0.0,[1.0,1.0,1.0,1.0,1.0,3.0])
(0.0,[1.0,1.0,1.0,1.0,1.0,2.0])
(0.0,[1.0,1.0,1.0,2.0,1.0,3.0])
(0.0,[1.0,1.0,1.0,2.0,1.0,1.0])
(0.0,[1.0,1.0,2.0,1.0,1.0,1.0])
(0.0,[3.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[2.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[1.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[3.0,1.0,1.0,1.0,2.0,2.0])
(0.0,[3.0,1.0,1.0,1.0,2.0,2.0])
(0.0,[2.0,1.0,1.0,1.0,1.0,2.0])
(0.0,[1.0,1.0,1.0,1.0,1.0,2.0])
(0.0,[1.0,3.0,1.0,1.0,1.0,1.0])
(0.0,[2.0,3.0,1.0,2.0,1.0,1.0])
(0.0,[1.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[1.0,1.0,1.0,2.0,1.0,2.0])
(0.0,[1.0,1.0,1.0,3.0,1.0,1.0])
(0.0,[1.0,1.0,1.0,1.0,1.0,3.0])
(0.0,[1.0,1.0,1.0,1.0,1.0,2.0])
(0.0,[1.0,1.0,1.0,2.0,1.0,3.0])
(0.0,[3.0,1.0,1.0,1.0,1.0,3.0])
(0.0,[3.0,2.0,1.0,1.0,1.0,1.0])
(0.0,[3.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[1.0,2.0,1.0,1.0,1.0,3.0])
(0.0,[1.0,1.0,1.0,1.0,1.0,2.0])
(0.0,[2.0,2.0,1.0,1.0,1.0,1.0])
(0.0,[2.0,2.0,1.0,1.0,1.0,1.0])
(0.0,[1.0,1.0,1.0,2.0,1.0,1.0])
(0.0,[1.0,1.0,2.0,1.0,1.0,1.0])
(0.0,[3.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[2.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[1.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[1.0,2.0,3.0,2.0,1.0,3.0])
(0.0,[3.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[1.0,2.0,1.0,1.0,1.0,3.0])
(0.0,[1.0,1.0,1.0,1.0,1.0,2.0])
(0.0,[2.0,2.0,1.0,1.0,1.0,1.0])
(0.0,[2.0,2.0,1.0,1.0,1.0,3.0])
(0.0,[2.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[3.0,2.0,1.0,1.0,1.0,2.0])
(0.0,[3.0,1.0,1.0,1.0,1.0,3.0])
(0.0,[3.0,2.0,1.0,1.0,1.0,1.0])
(0.0,[3.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[1.0,2.0,1.0,1.0,1.0,3.0])
(0.0,[1.0,1.0,1.0,1.0,1.0,2.0])
(0.0,[2.0,2.0,1.0,1.0,1.0,1.0])
(0.0,[2.0,2.0,1.0,1.0,1.0,1.0])
(0.0,[2.0,3.0,1.0,1.0,1.0,1.0])
(0.0,[3.0,2.0,1.0,1.0,1.0,1.0])
(0.0,[2.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[1.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[1.0,2.0,1.0,1.0,1.0,1.0])
(0.0,[2.0,1.0,1.0,1.0,1.0,2.0])
(0.0,[3.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[1.0,3.0,1.0,1.0,1.0,1.0])
(0.0,[2.0,3.0,1.0,2.0,1.0,1.0])
(0.0,[1.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[1.0,1.0,1.0,2.0,1.0,2.0])
(0.0,[1.0,1.0,1.0,1.0,1.0,3.0])
(0.0,[1.0,1.0,1.0,1.0,1.0,2.0])
(0.0,[1.0,1.0,1.0,2.0,1.0,3.0])
(0.0,[1.0,1.0,1.0,2.0,1.0,1.0])
(0.0,[1.0,1.0,2.0,1.0,1.0,1.0])
(0.0,[3.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[2.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[1.0,1.0,1.0,1.0,1.0,1.0])
(0.0,[3.0,1.0,1.0,1.0,2.0,2.0])
(1.0,[3.0,3.0,2.0,2.0,2.0,3.0])
(1.0,[1.0,1.0,2.0,2.0,2.0,1.0])
(1.0,[2.0,2.0,2.0,2.0,2.0,2.0])
(1.0,[3.0,3.0,3.0,3.0,3.0,3.0])
(1.0,[1.0,1.0,3.0,3.0,3.0,1.0])
(1.0,[2.0,2.0,3.0,3.0,3.0,2.0])
(1.0,[3.0,3.0,2.0,3.0,3.0,3.0])
(1.0,[3.0,3.0,3.0,2.0,2.0,3.0])
(1.0,[3.0,3.0,2.0,3.0,2.0,3.0])
(1.0,[3.0,3.0,2.0,2.0,3.0,3.0])
(1.0,[3.0,3.0,2.0,2.0,2.0,3.0])
(1.0,[1.0,1.0,2.0,2.0,2.0,1.0])
(1.0,[1.0,1.0,3.0,3.0,3.0,1.0])
(1.0,[2.0,2.0,3.0,3.0,3.0,2.0])
(1.0,[3.0,3.0,2.0,3.0,3.0,3.0])
(1.0,[3.0,3.0,3.0,2.0,2.0,3.0])
(1.0,[3.0,3.0,2.0,3.0,2.0,3.0])
(1.0,[1.0,1.0,2.0,3.0,2.0,1.0])
(1.0,[1.0,1.0,2.0,3.0,2.0,1.0])
(1.0,[1.0,1.0,2.0,2.0,3.0,1.0])
Training Error = 0.20408163265306123
import org.apache.spark.mllib.evaluation.MulticlassMetrics
import org.apache.spark.mllib.classification.{LogisticRegressionWithLBFGS, LogisticRegressionModel}
import org.apache.spark.mllib.regression.LabeledPoint
import org.apache.spark.mllib.linalg.{Vector, Vectors}
data: org.apache.spark.rdd.RDD[String] = /FileStore/tables/qt5qvaey1491163359132 MapPartitionsRDD[4950] at textFile at <console>:555
getDoubleValue: (input: String)Double
parsedData: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[4951] at map at <console>:570
splits: Array[org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint]] = Array(MapPartitionsRDD[4952] at randomSplit at <console>:579, MapPartitionsRDD[4953] at randomSplit at <console>:579)
trainingData: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[4952] at randomSplit at <console>:579
testData: org.apache.spark.rdd.RDD[org.apache.spark.mllib.regression.LabeledPoint] = MapPartitionsRDD[4953] at randomSplit at <console>:579
model: org.apache.spark.mllib.classification.LogisticRegressionModel = org.apache.spark.mllib.classification.LogisticRegressionModel: intercept = 0.0, numFeatures = 6, numClasses = 2, threshold = 0.5
parsedData1: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[4995] at map at <console>:587
labelAndPreds: org.apache.spark.rdd.RDD[(Double, Double)] = MapPartitionsRDD[4996] at map at <console>:590
trainErr: Double = 0.20408163265306123

Second Cell
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions.corr
import org.apache.spark.ml.regression.LinearRegression
import org.apache.spark.ml.feature.VectorAssembler
import org.apache.spark.ml.linalg.Vectors
import org.apache.spark.ml.evaluation.RegressionEvaluator
    val filePath = "/FileStore/tables/o1q3k3531491165543800/car_milage-6f50d.csv"
    val cars = spark.read.option("header","true"). option("inferSchema","true").csv(filePath)
    val cars1 = cars.na.drop() 
    val assembler = new VectorAssembler()
 assembler.setInputCols(Array("displacement","hp","torque","CRatio","RARatio","CarbBarrells","NoOfSpeed","length","width","weight","automatic"))
    assembler.setOutputCol("features")
    val cars2 = assembler.transform(cars1)
    cars2.show(40)
    val train = cars2.filter(cars1("weight") <= 4000)
    val test = cars2.filter(cars1("weight") > 4000)
    test.show()
    println("Train = "+train.count()+" Test = "+test.count())
        val algLR = new LinearRegression()
        algLR.setMaxIter(100)
        algLR.setRegParam(0.3)
        algLR.setElasticNetParam(0.8)
        algLR.setLabelCol("mpg")
        val mdlLR = algLR.fit(train)
        println(s"Coefficients: ${mdlLR.coefficients} Intercept: ${mdlLR.intercept}")
        val trSummary = mdlLR.summary
    println(s"numIterations: ${trSummary.totalIterations}")
    println(s"Iteration Summary History: ${trSummary.objectiveHistory.toList}")
    trSummary.residuals.show()
    println(s"RMSE: ${trSummary.rootMeanSquaredError}")
    println(s"r2: ${trSummary.r2}")
    val predictions = mdlLR.transform(test)
    predictions.show()
    val evaluator = new RegressionEvaluator()
        evaluator.setLabelCol("mpg")
        val rmse = evaluator.evaluate(predictions)
        println("Root Mean Squared Error = "+"%6.3f".format(rmse))
        evaluator.setMetricName("mse")
        val mse = evaluator.evaluate(predictions)
        println("Mean Squared Error = "+"%6.3f".format(mse))
    println("** That's All Folks **")   
+-----+------------+---+------+------+-------+------------+---------+------+-----+------+---------+--------------------+
|  mpg|displacement| hp|torque|CRatio|RARatio|CarbBarrells|NoOfSpeed|length|width|weight|automatic|            features|
+-----+------------+---+------+------+-------+------------+---------+------+-----+------+---------+--------------------+
| 18.9|       350.0|165|   260|   8.0|   2.56|           4|        3| 200.3| 69.9|  3910|        1|[350.0,165.0,260....|
| 17.0|       350.0|170|   275|   8.5|   2.56|           4|        3| 199.6| 72.9|  3860|        1|[350.0,170.0,275....|
| 20.0|       250.0|105|   185|  8.25|   2.73|           1|        3| 196.7| 72.2|  3510|        1|[250.0,105.0,185....|
|18.25|       351.0|143|   255|   8.0|    3.0|           2|        3| 199.9| 74.0|  3890|        1|[351.0,143.0,255....|
|20.07|       225.0| 95|   170|   8.4|   2.76|           1|        3| 194.1| 71.8|  3365|        0|[225.0,95.0,170.0...|
| 11.2|       440.0|215|   330|   8.2|   2.88|           4|        3| 184.5| 69.0|  4215|        1|[440.0,215.0,330....|
|22.12|       231.0|110|   175|   8.0|   2.56|           2|        3| 179.3| 65.4|  3020|        1|[231.0,110.0,175....|
|21.47|       262.0|110|   200|   8.5|   2.56|           2|        3| 179.3| 65.4|  3180|        1|[262.0,110.0,200....|
| 34.7|        89.7| 70|    81|   8.2|    3.9|           2|        4| 155.7| 64.0|  1905|        0|[89.7,70.0,81.0,8...|
| 30.4|        96.9| 75|    83|   9.0|    4.3|           2|        5| 165.2| 65.0|  2320|        0|[96.9,75.0,83.0,9...|
| 16.5|       350.0|155|   250|   8.5|   3.08|           4|        3| 195.4| 74.4|  3885|        1|[350.0,155.0,250....|
| 36.5|        85.3| 80|    83|   8.5|   3.89|           2|        4| 160.6| 62.2|  2009|        0|[85.3,80.0,83.0,8...|
| 21.5|       171.0|109|   146|   8.2|   3.22|           2|        4| 170.4| 66.9|  2655|        0|[171.0,109.0,146....|
| 19.7|       258.0|110|   195|   8.0|   3.08|           1|        3| 171.5| 77.0|  3375|        1|[258.0,110.0,195....|
| 20.3|       140.0| 83|   109|   8.4|    3.4|           2|        4| 168.8| 69.4|  2700|        0|[140.0,83.0,109.0...|
| 17.8|       302.0|129|   220|   8.0|    3.0|           2|        3| 199.9| 74.0|  3890|        1|[302.0,129.0,220....|
|14.39|       500.0|190|   360|   8.5|   2.73|           4|        3| 224.1| 79.8|  5290|        1|[500.0,190.0,360....|
|14.89|       440.0|215|   330|   8.2|   2.71|           4|        3| 231.0| 79.7|  5185|        1|[440.0,215.0,330....|
| 17.8|       350.0|155|   250|   8.5|   3.08|           4|        3| 196.7| 72.2|  3910|        1|[350.0,155.0,250....|
|16.41|       318.0|145|   255|   8.5|   2.45|           2|        3| 197.6| 71.0|  3660|        1|[318.0,145.0,255....|
|23.54|       231.0|110|   175|   8.0|   2.56|           2|        3| 179.3| 65.4|  3050|        1|[231.0,110.0,175....|
|21.47|       360.0|180|   290|   8.4|   2.45|           2|        3| 214.2| 76.3|  4250|        1|[360.0,180.0,290....|
| 31.9|        96.9| 75|    83|   9.0|    4.3|           2|        5| 165.2| 61.8|  2275|        0|[96.9,75.0,83.0,9...|
|13.27|       460.0|223|   366|   8.0|    3.0|           4|        3| 228.0| 79.8|  5430|        1|[460.0,223.0,366....|
| 23.9|       133.6| 96|   120|   8.4|   3.91|           2|        5| 171.5| 63.4|  2535|        0|[133.6,96.0,120.0...|
|19.73|       318.0|140|   255|   8.5|   2.71|           2|        3| 215.3| 76.3|  4370|        1|[318.0,140.0,255....|
| 13.9|       351.0|148|   243|   8.0|   3.25|           2|        3| 215.5| 78.5|  4540|        1|[351.0,148.0,243....|
|13.27|       351.0|148|   243|   8.0|   3.26|           2|        3| 216.1| 78.5|  4715|        1|[351.0,148.0,243....|
|13.77|       360.0|195|   295|  8.25|   3.15|           4|        3| 209.3| 77.4|  4215|        1|[360.0,195.0,295....|
| 16.5|       360.0|165|   255|   8.5|   2.73|           4|        3| 185.2| 69.0|  3660|        1|[360.0,165.0,255....|
+-----+------------+---+------+------+-------+------------+---------+------+-----+------+---------+--------------------+

+-----+------------+---+------+------+-------+------------+---------+------+-----+------+---------+--------------------+
|  mpg|displacement| hp|torque|CRatio|RARatio|CarbBarrells|NoOfSpeed|length|width|weight|automatic|            features|
+-----+------------+---+------+------+-------+------------+---------+------+-----+------+---------+--------------------+
| 11.2|       440.0|215|   330|   8.2|   2.88|           4|        3| 184.5| 69.0|  4215|        1|[440.0,215.0,330....|
|14.39|       500.0|190|   360|   8.5|   2.73|           4|        3| 224.1| 79.8|  5290|        1|[500.0,190.0,360....|
|14.89|       440.0|215|   330|   8.2|   2.71|           4|        3| 231.0| 79.7|  5185|        1|[440.0,215.0,330....|
|21.47|       360.0|180|   290|   8.4|   2.45|           2|        3| 214.2| 76.3|  4250|        1|[360.0,180.0,290....|
|13.27|       460.0|223|   366|   8.0|    3.0|           4|        3| 228.0| 79.8|  5430|        1|[460.0,223.0,366....|
|19.73|       318.0|140|   255|   8.5|   2.71|           2|        3| 215.3| 76.3|  4370|        1|[318.0,140.0,255....|
| 13.9|       351.0|148|   243|   8.0|   3.25|           2|        3| 215.5| 78.5|  4540|        1|[351.0,148.0,243....|
|13.27|       351.0|148|   243|   8.0|   3.26|           2|        3| 216.1| 78.5|  4715|        1|[351.0,148.0,243....|
|13.77|       360.0|195|   295|  8.25|   3.15|           4|        3| 209.3| 77.4|  4215|        1|[360.0,195.0,295....|
+-----+------------+---+------+------+-------+------------+---------+------+-----+------+---------+--------------------+

Train = 21 Test = 9
Coefficients: [0.0,-0.007017141998245329,0.0,0.0,2.9424064428541645,0.0,-0.8628157004496956,0.0,-0.26534908526629886,-0.004729717739392178,0.0] Intercept: 50.05862655261031
numIterations: 101
Iteration Summary History: List(0.4999999999999991, 0.39843747544896296, 0.1482295744826868, 0.14005807692077016, 0.1446968308765583, 0.12669217682960035, 0.1258630122249318, 0.12511340526765194, 0.12322427437191928, 0.12276798916627535, 0.12223083208160618, 0.12198963359328388, 0.1217980834932178, 0.12150878758627376, 0.1213259562375511, 0.12091301876948132, 0.12028626315701765, 0.12005169278210738, 0.11977289314390564, 0.1194232265949696, 0.11834850015514281, 0.1181617248486041, 0.11798849972869874, 0.1177544183274557, 0.11764132783918399, 0.11761053226921289, 0.1175372291362528, 0.11740134195406475, 0.11730833333681416, 0.11717018963534281, 0.11717255191139506, 0.11715818488156707, 0.11713935699462788, 0.1171267413739083, 0.11711722997357507, 0.11710097506014061, 0.11710017828208376, 0.11709947582555068, 0.11709917904474389, 0.11709768838483264, 0.1170929119008887, 0.11708390851967115, 0.11707212479832396, 0.1170662760037003, 0.11706127166256519, 0.1170522477334453, 0.11704956881759424, 0.11704258835326761, 0.11703425632000736, 0.11703156832900255, 0.11702939448133705, 0.1170287537028389, 0.11702848337455823, 0.11702624620585331, 0.11702621917586575, 0.11702618327298192, 0.11702613294793285, 0.11702611993473151, 0.11702611478925005, 0.11702610986218365, 0.1170260926507051, 0.11702609220245044, 0.11702609164365266, 0.11702609140604611, 0.11702609131291232, 0.11702609126614305, 0.11702609123924826, 0.11702609122479349, 0.11702609121648369, 0.11702609118295512, 0.11702609115548301, 0.11702609114831418, 0.11702609112982439, 0.11702609111569616, 0.11702609110533795, 0.11702609107307879, 0.11702609106553438, 0.11702609104277378, 0.11702609103254892, 0.11702609102831152, 0.11702609102006481, 0.1170260910096031, 0.11702609100701458, 0.11702609100499353, 0.11702609100337794, 0.11702609100260936, 0.11702609100161605, 0.11702609099996845, 0.11702609099909858, 0.11702609099704782, 0.11702609099464559, 0.11702609099325104, 0.11702609099095895, 0.11702609099070427, 0.11702609099051453, 0.11702609099025423, 0.1170260909899599, 0.11702609098981817, 0.1170260909895432, 0.11702609098949088, 0.11702609098940772)
+--------------------+
|           residuals|
+--------------------+
|   2.096185905880297|
|  0.7908329847008133|
|  0.9933640910559873|
|   0.990486841867046|
| 0.11297177146952109|
|-0.47327657578057725|
| -0.3665217374778287|
|    3.10090481251963|
|  0.7500255929329356|
| -0.8282089241727775|
|    5.01476258834807|
|  -3.507789616591573|
|   0.333771260508545|
| -4.5436584568213085|
|  0.4422468538916142|
|0.006266031726166688|
| -1.1010376664257713|
|  1.0886149564011873|
|    1.18807122180813|
| -3.8627451348475503|
+--------------------+
only showing top 20 rows

RMSE: 2.185539052409796
r2: 0.864032450749066
+-----+------------+---+------+------+-------+------------+---------+------+-----+------+---------+--------------------+------------------+
|  mpg|displacement| hp|torque|CRatio|RARatio|CarbBarrells|NoOfSpeed|length|width|weight|automatic|            features|        prediction|
+-----+------------+---+------+------+-------+------------+---------+------+-----+------+---------+--------------------+------------------+
| 11.2|       440.0|215|   330|   8.2|   2.88|           4|        3| 184.5| 69.0|  4215|        1|[440.0,215.0,330....|16.190777322145827|
|14.39|       500.0|190|   360|   8.5|   2.73|           4|        3| 224.1| 79.8|  5290|        1|[500.0,190.0,360....| 7.974628214951217|
|14.89|       440.0|215|   330|   8.2|   2.71|           4|        3| 231.0| 79.7|  5185|        1|[440.0,215.0,330....| 8.263506807300807|
|21.47|       360.0|180|   290|   8.4|   2.45|           2|        3| 214.2| 76.3|  4250|        1|[360.0,180.0,290....|13.068554078334408|
|13.27|       460.0|223|   366|   8.0|    3.0|           4|        3| 228.0| 79.8|  5430|        1|[460.0,223.0,366....| 7.875351785064844|
|19.73|       318.0|140|   255|   8.5|   2.71|           2|        3| 215.3| 76.3|  4370|        1|[318.0,140.0,255....|13.546699304679244|
| 13.9|       351.0|148|   243|   8.0|   3.25|           2|        3| 215.5| 78.5|  4540|        1|[351.0,148.0,243....|13.691641644552007|
|13.27|       351.0|148|   243|   8.0|   3.26|           2|        3| 216.1| 78.5|  4715|        1|[351.0,148.0,243....|12.893365104586913|
|13.77|       360.0|195|   295|  8.25|   3.15|           4|        3| 209.3| 77.4|  4215|        1|[360.0,195.0,295....|14.896637585444445|
+-----+------------+---+------+------+-------+------------+---------+------+-----+------+---------+--------------------+------------------+

Root Mean Squared Error =  5.264
Mean Squared Error = 27.706
** That's All Folks **
import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions.corr
import org.apache.spark.ml.regression.LinearRegression
import org.apache.spark.ml.feature.VectorAssembler
import org.apache.spark.ml.linalg.Vectors
import org.apache.spark.ml.evaluation.RegressionEvaluator
filePath: String = /FileStore/tables/o1q3k3531491165543800/car_milage-6f50d.csv
cars: org.apache.spark.sql.DataFrame = [mpg: double, displacement: double ... 10 more fields]
cars1: org.apache.spark.sql.DataFrame = [mpg: double, displacement: double ... 10 more fields]
assembler: org.apache.spark.ml.feature.VectorAssembler = vecAssembler_91645462844e
cars2: org.apache.spark.sql.DataFrame = [mpg: double, displacement: double ... 11 more fields]
train: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [mpg: double, displacement: double ... 11 more fields]
test: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [mpg: double, displacement: double ... 11 more fields]
algLR: org.apache.spark.ml.regression.LinearRegression = linReg_c82d1a720ff8
mdlLR: org.apache.spark.ml.regression.LinearRegressionModel = linReg_c82d1a720ff8
trSummary: org.apache.spark.ml.regression.LinearRegressionTrainingSummary = org.apache.spark.ml.regression.LinearRegressionTrainingSummary@1613e6b6
predictions: org.apache.spark.sql.DataFrame = [mpg: double, displacement: double ... 12 more fields]
evaluator: org.apache.spark.ml.evaluation.RegressionEvaluator = regEval_9a7ee110fd81
rmse: Double = 5.263602222142872
mse: Double = 27.705508352947376
import org.apache.spark.mllib.fpm.FPGrowth
import org.apache.spark.rdd.RDD
val data = sc.textFile("/databricks-datasets/samples/data/mllib/sample_fpgrowth.txt")
val transactions: RDD[Array[String]] = data.map(s => s.trim.split(' '))
val fpg = new FPGrowth()
  .setMinSupport(0.2)
  .setNumPartitions(10)
val model = fpg.run(transactions)
model.freqItemsets.collect().foreach { itemset =>
  println(itemset.items.mkString("[", ",", "]") + ", " + itemset.freq)
}
val minConfidence = 0.8
model.generateAssociationRules(minConfidence).collect().foreach { rule =>
  println(
    rule.antecedent.mkString("[", ",", "]")
      + " => " + rule.consequent .mkString("[", ",", "]")
      + ", " + rule.confidence)
}

[z], 5
[x], 4
[x,z], 3
[y], 3
[y,x], 3
[y,x,z], 3
[y,z], 3
[r], 3
[r,x], 2
[r,z], 2
[s], 3
[s,y], 2
[s,y,x], 2
[s,y,x,z], 2
[s,y,z], 2
[s,x], 3
[s,x,z], 2
[s,z], 2
[t], 3
[t,y], 3
[t,y,x], 3
[t,y,x,z], 3
[t,y,z], 3
[t,s], 2
[t,s,y], 2
[t,s,y,x], 2
[t,s,y,x,z], 2
[t,s,y,z], 2
[t,s,x], 2
[t,s,x,z], 2
[t,s,z], 2
[t,x], 3
[t,x,z], 3
[t,z], 3
[p], 2
[p,r], 2
[p,r,z], 2
[p,z], 2
[q], 2
[q,y], 2
[q,y,x], 2
[q,y,x,z], 2
[q,y,z], 2
[q,t], 2
[q,t,y], 2
[q,t,y,x], 2
[q,t,y,x,z], 2
[q,t,y,z], 2
[q,t,x], 2
[q,t,x,z], 2
[q,t,z], 2
[q,x], 2
[q,x,z], 2
[q,z], 2
[t,s,y] => [x], 1.0
[t,s,y] => [z], 1.0
[y,x,z] => [t], 1.0
[y] => [x], 1.0
[y] => [z], 1.0
[y] => [t], 1.0
[p] => [r], 1.0
[p] => [z], 1.0
[q,t,z] => [y], 1.0
[q,t,z] => [x], 1.0
[q,y] => [x], 1.0
[q,y] => [z], 1.0
[q,y] => [t], 1.0
[t,s,x] => [y], 1.0
[t,s,x] => [z], 1.0
[q,t,y,z] => [x], 1.0
[q,t,x,z] => [y], 1.0
[q,x] => [y], 1.0
[q,x] => [t], 1.0
[q,x] => [z], 1.0
[t,x,z] => [y], 1.0
[x,z] => [y], 1.0
[x,z] => [t], 1.0
[p,z] => [r], 1.0
[t] => [y], 1.0
[t] => [x], 1.0
[t] => [z], 1.0
[y,z] => [x], 1.0
[y,z] => [t], 1.0
[p,r] => [z], 1.0
[t,s] => [y], 1.0
[t,s] => [x], 1.0
[t,s] => [z], 1.0
[q,z] => [y], 1.0
[q,z] => [t], 1.0
[q,z] => [x], 1.0
[q,y,z] => [x], 1.0
[q,y,z] => [t], 1.0
[y,x] => [z], 1.0
[y,x] => [t], 1.0
[q,x,z] => [y], 1.0
[q,x,z] => [t], 1.0
[t,y,z] => [x], 1.0
[q,y,x] => [z], 1.0
[q,y,x] => [t], 1.0
[q,t,y,x] => [z], 1.0
[t,s,x,z] => [y], 1.0
[s,y,x] => [z], 1.0
[s,y,x] => [t], 1.0
[s,x,z] => [y], 1.0
[s,x,z] => [t], 1.0
[q,y,x,z] => [t], 1.0
[s,y] => [x], 1.0
[s,y] => [z], 1.0
[s,y] => [t], 1.0
[q,t,y] => [x], 1.0
[q,t,y] => [z], 1.0
[t,y] => [x], 1.0
[t,y] => [z], 1.0
[t,z] => [y], 1.0
[t,z] => [x], 1.0
[t,s,y,x] => [z], 1.0
[t,y,x] => [z], 1.0
[q,t] => [y], 1.0
[q,t] => [x], 1.0
[q,t] => [z], 1.0
[q] => [y], 1.0
[q] => [t], 1.0
[q] => [x], 1.0
[q] => [z], 1.0
[t,s,z] => [y], 1.0
[t,s,z] => [x], 1.0
[t,x] => [y], 1.0
[t,x] => [z], 1.0
[s,z] => [y], 1.0
[s,z] => [x], 1.0
[s,z] => [t], 1.0
[s,y,x,z] => [t], 1.0
[s] => [x], 1.0
[t,s,y,z] => [x], 1.0
[s,y,z] => [x], 1.0
[s,y,z] => [t], 1.0
[q,t,x] => [y], 1.0
[q,t,x] => [z], 1.0
[r,z] => [p], 1.0
import org.apache.spark.mllib.fpm.FPGrowth
import org.apache.spark.rdd.RDD
data: org.apache.spark.rdd.RDD[String] = /databricks-datasets/samples/data/mllib/sample_fpgrowth.txt MapPartitionsRDD[5065] at textFile at <console>:558
transactions: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[5066] at map at <console>:559
fpg: org.apache.spark.mllib.fpm.FPGrowth = org.apache.spark.mllib.fpm.FPGrowth@2a95b53e
model: org.apache.spark.mllib.fpm.FPGrowthModel[String] = org.apache.spark.mllib.fpm.FPGrowthModel@64015ef9
minConfidence: Double = 0.8
import org.apache.spark.sql.functions._
val filePath = "/FileStore/tables/h2tqh7vb1491165896749/car_milage_csv-9d74c.1"
val cars = spark.read.option("header","true"). option("inferSchema","true").csv(filePath)
println("Cars has "+ cars.count() +" rows") 
// Show the top 5 cars in the dataset
cars.show(5) 

// Print the schema of the dataset
cars.printSchema()
// Let's run some statistical functions

// Find summary of the following columns - mpg,hp,weight,automatic
cars.select("mpg","hp","weight","automatic").show()

// Run the following query - What is the average mpg and torque of the automatic and non-automatic cars?
// org.apache.spark.sql.AnalysisException: cannot resolve '`mpg`' given input columns: [automatic];;
// cars.select("automatic").describe("mpg","torque").show()

// Find the overall average mpg and torque of all the cars together
cars.select(mean(cars("mpg")), mean(cars("torque")) ).show()

// Find the correlation coefficient between weight and hp for all cars. Display only 4 decimal points
val cor = cars.stat.corr("hp","weight") 
println("hp to weight : Correlation = %.4f".format(cor))
Cars has 32 rows
+-----+------------+---+------+------+-------+------------+---------+------+-----+------+---------+
|  mpg|displacement| hp|torque|CRatio|RARatio|CarbBarrells|NoOfSpeed|length|width|weight|automatic|
+-----+------------+---+------+------+-------+------------+---------+------+-----+------+---------+
| 18.9|       350.0|165|   260|   8.0|   2.56|           4|        3| 200.3| 69.9|  3910|        1|
| 17.0|       350.0|170|   275|   8.5|   2.56|           4|        3| 199.6| 72.9|  3860|        1|
| 20.0|       250.0|105|   185|  8.25|   2.73|           1|        3| 196.7| 72.2|  3510|        1|
|18.25|       351.0|143|   255|   8.0|    3.0|           2|        3| 199.9| 74.0|  3890|        1|
|20.07|       225.0| 95|   170|   8.4|   2.76|           1|        3| 194.1| 71.8|  3365|        0|
+-----+------------+---+------+------+-------+------------+---------+------+-----+------+---------+
only showing top 5 rows

root
 |-- mpg: double (nullable = true)
 |-- displacement: double (nullable = true)
 |-- hp: integer (nullable = true)
 |-- torque: integer (nullable = true)
 |-- CRatio: double (nullable = true)
 |-- RARatio: double (nullable = true)
 |-- CarbBarrells: integer (nullable = true)
 |-- NoOfSpeed: integer (nullable = true)
 |-- length: double (nullable = true)
 |-- width: double (nullable = true)
 |-- weight: integer (nullable = true)
 |-- automatic: integer (nullable = true)

+-----+---+------+---------+
|  mpg| hp|weight|automatic|
+-----+---+------+---------+
| 18.9|165|  3910|        1|
| 17.0|170|  3860|        1|
| 20.0|105|  3510|        1|
|18.25|143|  3890|        1|
|20.07| 95|  3365|        0|
| 11.2|215|  4215|        1|
|22.12|110|  3020|        1|
|21.47|110|  3180|        1|
| 34.7| 70|  1905|        0|
| 30.4| 75|  2320|        0|
| 16.5|155|  3885|        1|
| 36.5| 80|  2009|        0|
| 21.5|109|  2655|        0|
| 19.7|110|  3375|        1|
| 20.3| 83|  2700|        0|
| 17.8|129|  3890|        1|
|14.39|190|  5290|        1|
|14.89|215|  5185|        1|
| 17.8|155|  3910|        1|
|16.41|145|  3660|        1|
+-----+---+------+---------+
only showing top 20 rows

+---------+-----------+
| avg(mpg)|avg(torque)|
+---------+-----------+
|20.223125|      217.9|
+---------+-----------+

hp to weight : Correlation = 0.8834
import org.apache.spark.sql.functions._
filePath: String = /FileStore/tables/h2tqh7vb1491165896749/car_milage_csv-9d74c.1
cars: org.apache.spark.sql.DataFrame = [mpg: double, displacement: double ... 10 more fields]
cor: Double = 0.8834003785623672
import org.apache.spark.sql.functions._
val filePath = "/FileStore/tables/0bbiuyxm1491172678670/titanic3_02.csv" 
val passengers = spark.read.option("header","true"). option("inferSchema","true"). csv(filePath) 
// How many passengers were there on titanic?
println("Passengers has "+ passengers.count() +" rows")
// Let's get the columns that we need further
val passengers1 = passengers.select(passengers("Pclass"),passengers("Survived"),passengers("Gender"),passengers("Age"),passengers("SibSp"),passengers("Parch"),passengers("Fare"))
// print the schema of passengers1
passengers1.printSchema()
// Let's run some queries
// Find the gender distribution of passengers
passengers1.alias("Gender").show() 
// We would like to find out the joint distribution of gender and survived columns i.e. what is the number of males and females that survived
passengers1.stat.crosstab("Survived","Gender").show() 
Passengers has 1309 rows
root
 |-- Pclass: integer (nullable = true)
 |-- Survived: integer (nullable = true)
 |-- Gender: string (nullable = true)
 |-- Age: double (nullable = true)
 |-- SibSp: integer (nullable = true)
 |-- Parch: integer (nullable = true)
 |-- Fare: double (nullable = true)

+------+--------+------+------+-----+-----+--------+
|Pclass|Survived|Gender|   Age|SibSp|Parch|    Fare|
+------+--------+------+------+-----+-----+--------+
|     1|       1|female|  29.0|    0|    0|211.3375|
|     1|       1|  male|0.9167|    1|    2|  151.55|
|     1|       0|female|   2.0|    1|    2|  151.55|
|     1|       0|  male|  30.0|    1|    2|  151.55|
|     1|       0|female|  25.0|    1|    2|  151.55|
|     1|       1|  male|  48.0|    0|    0|   26.55|
|     1|       1|female|  63.0|    1|    0| 77.9583|
|     1|       0|  male|  39.0|    0|    0|     0.0|
|     1|       1|female|  53.0|    2|    0| 51.4792|
|     1|       0|  male|  71.0|    0|    0| 49.5042|
|     1|       0|  male|  47.0|    1|    0| 227.525|
|     1|       1|female|  18.0|    1|    0| 227.525|
|     1|       1|female|  24.0|    0|    0|    69.3|
|     1|       1|female|  26.0|    0|    0|   78.85|
|     1|       1|  male|  80.0|    0|    0|    30.0|
|     1|       0|  male|  null|    0|    0|  25.925|
|     1|       0|  male|  24.0|    0|    1|247.5208|
|     1|       1|female|  50.0|    0|    1|247.5208|
|     1|       1|female|  32.0|    0|    0| 76.2917|
|     1|       0|  male|  36.0|    0|    0| 75.2417|
+------+--------+------+------+-----+-----+--------+
only showing top 20 rows

+---------------+------+----+
|Survived_Gender|female|male|
+---------------+------+----+
|              1|   339| 161|
|              0|   127| 682|
+---------------+------+----+

import org.apache.spark.sql.functions._
filePath: String = /FileStore/tables/0bbiuyxm1491172678670/titanic3_02.csv
passengers: org.apache.spark.sql.DataFrame = [Pclass: int, Survived: int ... 12 more fields]
passengers1: org.apache.spark.sql.DataFrame = [Pclass: int, Survived: int ... 5 more fields]
import org.apache.spark.ml.{Pipeline, PipelineModel}
import org.apache.spark.ml.classification.LogisticRegression
import org.apache.spark.ml.feature.{HashingTF, Tokenizer}
import org.apache.spark.ml.linalg.Vector
import org.apache.spark.sql.Row

// Prepare training documents from a list of (id, text, label) tuples.
val training = spark.createDataFrame(Seq(
  (0L, "a b c d e spark", 1.0),
  (1L, "b d", 0.0),
  (2L, "spark f g h", 1.0),
  (3L, "hadoop mapreduce", 0.0)
)).toDF("id", "text", "label")

// Configure an ML pipeline, which consists of three stages: tokenizer, hashingTF, and lr.
val tokenizer = new Tokenizer()
  .setInputCol("text")
  .setOutputCol("words")
val hashingTF = new HashingTF()
  .setNumFeatures(1000)
  .setInputCol(tokenizer.getOutputCol)
  .setOutputCol("features")
val lr = new LogisticRegression()
  .setMaxIter(10)
  .setRegParam(0.001)
val pipeline = new Pipeline()
  .setStages(Array(tokenizer, hashingTF, lr))
// Fit the pipeline to training documents.
val model = pipeline.fit(training)

// Now we can optionally save the fitted pipeline to disk
model.write.overwrite().save("/tmp/spark-logistic-regression-model")

// We can also save this unfit pipeline to disk
pipeline.write.overwrite().save("/tmp/unfit-lr-model")

// And load it back in during production
val sameModel = PipelineModel.load("/tmp/spark-logistic-regression-model")

// Prepare test documents, which are unlabeled (id, text) tuples.
val test = spark.createDataFrame(Seq(
  (4L, "spark i j k"),
  (5L, "l m n"),
  (6L, "spark hadoop spark"),
  (7L, "apache hadoop")
)).toDF("id", "text")

// Make predictions on test documents.
model.transform(test)
  .select("id", "text", "probability", "prediction")
  .collect()
  .foreach { case Row(id: Long, text: String, prob: Vector, prediction: Double) =>
    println(s"($id, $text) --> prob=$prob, prediction=$prediction")
  }
(4, spark i j k) --> prob=[0.15964077387874112,0.8403592261212589], prediction=1.0
(5, l m n) --> prob=[0.8378325685476613,0.16216743145233867], prediction=0.0
(6, spark hadoop spark) --> prob=[0.06926633132976262,0.9307336686702374], prediction=1.0
(7, apache hadoop) --> prob=[0.9821575333444208,0.01784246665557917], prediction=0.0
import org.apache.spark.ml.{Pipeline, PipelineModel}
import org.apache.spark.ml.classification.LogisticRegression
import org.apache.spark.ml.feature.{HashingTF, Tokenizer}
import org.apache.spark.ml.linalg.Vector
import org.apache.spark.sql.Row
training: org.apache.spark.sql.DataFrame = [id: bigint, text: string ... 1 more field]
tokenizer: org.apache.spark.ml.feature.Tokenizer = tok_8fc6ed022b34
hashingTF: org.apache.spark.ml.feature.HashingTF = hashingTF_96aa60156264
lr: org.apache.spark.ml.classification.LogisticRegression = logreg_4d7a265859f5
pipeline: org.apache.spark.ml.Pipeline = pipeline_b8dfb05a6e8b
model: org.apache.spark.ml.PipelineModel = pipeline_b8dfb05a6e8b
sameModel: org.apache.spark.ml.PipelineModel = pipeline_b8dfb05a6e8b
test: org.apache.spark.sql.DataFrame = [id: bigint, text: string]
import org.apache.spark.ml.Pipeline
import org.apache.spark.ml.classification.LogisticRegression
import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator
import org.apache.spark.ml.feature.{HashingTF, Tokenizer}
import org.apache.spark.ml.linalg.Vector
import org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder}
import org.apache.spark.sql.Row

// Prepare training data from a list of (id, text, label) tuples.
val training = spark.createDataFrame(Seq(
  (0L, "a b c d e spark", 1.0),
  (1L, "b d", 0.0),
  (2L, "spark f g h", 1.0),
  (3L, "hadoop mapreduce", 0.0),
  (4L, "b spark who", 1.0),
  (5L, "g d a y", 0.0),
  (6L, "spark fly", 1.0),
  (7L, "was mapreduce", 0.0),
  (8L, "e spark program", 1.0),
  (9L, "a e c l", 0.0),
  (10L, "spark compile", 1.0),
  (11L, "hadoop software", 0.0)
)).toDF("id", "text", "label")

// Configure an ML pipeline, which consists of three stages: tokenizer, hashingTF, and lr.
val tokenizer = new Tokenizer()
  .setInputCol("text")
  .setOutputCol("words")
val hashingTF = new HashingTF()
  .setInputCol(tokenizer.getOutputCol)
  .setOutputCol("features")
val lr = new LogisticRegression()
  .setMaxIter(10)
val pipeline = new Pipeline()
  .setStages(Array(tokenizer, hashingTF, lr))

// We use a ParamGridBuilder to construct a grid of parameters to search over.
// With 3 values for hashingTF.numFeatures and 2 values for lr.regParam,
// this grid will have 3 x 2 = 6 parameter settings for CrossValidator to choose from.
val paramGrid = new ParamGridBuilder()
  .addGrid(hashingTF.numFeatures, Array(10, 100, 1000))
  .addGrid(lr.regParam, Array(0.1, 0.01))
  .build()

// We now treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.
// This will allow us to jointly choose parameters for all Pipeline stages.
// A CrossValidator requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.
// Note that the evaluator here is a BinaryClassificationEvaluator and its default metric
// is areaUnderROC.
val cv = new CrossValidator()
  .setEstimator(pipeline)
  .setEvaluator(new BinaryClassificationEvaluator)
  .setEstimatorParamMaps(paramGrid)
  .setNumFolds(2)  // Use 3+ in practice

// Run cross-validation, and choose the best set of parameters.
val cvModel = cv.fit(training)

// Prepare test documents, which are unlabeled (id, text) tuples.
val test = spark.createDataFrame(Seq(
  (4L, "spark i j k"),
  (5L, "l m n"),
  (6L, "mapreduce spark"),
  (7L, "apache hadoop")
)).toDF("id", "text")

// Make predictions on test documents. cvModel uses the best model found (lrModel).
cvModel.transform(test)
  .select("id", "text", "probability", "prediction")
  .collect()
  .foreach { case Row(id: Long, text: String, prob: Vector, prediction: Double) =>
    println(s"($id, $text) --> prob=$prob, prediction=$prediction")
  }
(4, spark i j k) --> prob=[0.12566260711357224,0.8743373928864279], prediction=1.0
(5, l m n) --> prob=[0.995215441016286,0.004784558983714], prediction=0.0
(6, mapreduce spark) --> prob=[0.30696895232625965,0.6930310476737404], prediction=1.0
(7, apache hadoop) --> prob=[0.8040279442401378,0.19597205575986223], prediction=0.0
import org.apache.spark.ml.Pipeline
import org.apache.spark.ml.classification.LogisticRegression
import org.apache.spark.ml.evaluation.BinaryClassificationEvaluator
import org.apache.spark.ml.feature.{HashingTF, Tokenizer}
import org.apache.spark.ml.linalg.Vector
import org.apache.spark.ml.tuning.{CrossValidator, ParamGridBuilder}
import org.apache.spark.sql.Row
training: org.apache.spark.sql.DataFrame = [id: bigint, text: string ... 1 more field]
tokenizer: org.apache.spark.ml.feature.Tokenizer = tok_fa350c3152a0
hashingTF: org.apache.spark.ml.feature.HashingTF = hashingTF_6d6c2158b636
lr: org.apache.spark.ml.classification.LogisticRegression = logreg_825587a8adaa
pipeline: org.apache.spark.ml.Pipeline = pipeline_146b921b8a65
paramGrid: Array[org.apache.spark.ml.param.ParamMap] = 
Array({
	hashingTF_6d6c2158b636-numFeatures: 10,
	logreg_825587a8adaa-regParam: 0.1
}, {
	hashingTF_6d6c2158b636-numFeatures: 10,
	logreg_825587a8adaa-regParam: 0.01
}, {
	hashingTF_6d6c2158b636-numFeatures: 100,
	logreg_825587a8adaa-regParam: 0.1
}, {
	hashingTF_6d6c2158b636-numFeatures: 100,
	logreg_825587a8adaa-regParam: 0.01
}, {
	hashingTF_6d6c2158b636-numFeatures: 1000,
	logreg_825587a8adaa-regParam: 0.1
}, {
	hashingTF_6d6c2158b636-numFeatures: 1000,
	logreg_825587a8adaa-regParam: 0.01
})
cv: org.apache.spark.ml.tuning.CrossValidator = cv_a8ab707c3d8a
cvModel: org.apache.spark.ml.tuning.CrossValidatorModel = cv_a8ab707c3d8a
test: org.apache.spark.sql.DataFrame = [id: bigint, text: string]
